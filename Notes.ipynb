{
 "metadata": {
  "name": "",
  "signature": "sha256:fcbfa775150a40e88c49b2a5abbeefd2d66b8314c04d378746521939f15ba622"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Representing $\\vec x\\in\\mathbb R^m$ with neurons"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "According to classical artificial neural network theory, for an input vector $\\vec x=(x_1,...,x_m)\\in\\mathbb R^m$, a neuron $i$ has an output \n",
      "\n",
      "$$a_i=G(\\Sigma _{j=1}^m w_{ij}\\cdot x_j+b_i)$$\n",
      "\n",
      "where $w_1,...,w_m\\in\\mathbb R^m$ are weights on each input value and $b_i\\in\\mathbb R$ is a constant bias term. $G(J)$ is (almost always) a real-valued function and is usually (though not necessarily) non-decreasing; it is sometimes called the transfer function. Popular versions of $G$ familiar from connectionism are threshold functions, sigmoid functions, rectified linear functions etc. What function you choose depends on what you want to do, including how biologically accurate you want your model to be.\n",
      "\n",
      "Anyway, we can make our way towards the NEF way of thinking about neural representation from here. First notice that\n",
      "\n",
      "$$a_i=G(\\vec x\\cdot \\vec w_i+b_i)$$\n",
      "\n",
      "where $\\vec w_i=(w_1,...,w_m)$. Now we can write \n",
      "\n",
      "$$\\vec w_i = \\alpha _i\\vec e_i$$ \n",
      "\n",
      "where $\\alpha _i= |w_i|$ (and consequently $|e_i|=\\left|\\frac{\\vec w_i}{|w_i|}\\right|=1$). So now we have \n",
      "\n",
      "$$a_i=G(\\alpha _i\\vec x\\cdot \\vec e_i+b_i)$$. \n",
      "\n",
      "(Compare this to the Representation lecture for SYDE556.) The difference between this and the above is mostly notational, but it lets us interpret what is going on with the neuron very nicely. First, $\\vec x\\cdot\\vec e_i=|\\vec x||\\vec e_i|\\cos\\theta=|\\vec x|\\cos\\theta$, where $\\theta$ is the angle between $\\vec x$ and $\\vec e_i$. Consequently $|\\vec x\\cdot\\vec e_i|$ is maximal when $x$ and $e_i$ are colinear. We can think of $e_i$ as determining the preferred axis of neuron $i$. Then $|\\vec e_i\\cdot\\vec x|$ is a measure of the size of the component of $\\vec x$ on the axis of $\\vec e_i$ relative to $\\vec e_i$. The sign of $\\vec e_i\\cdot\\vec x$ tells us if $\\vec x$ is generally pointing in the direction of $e_i$ or not. $\\alpha_i$ is a gain term and determines how sensitive the neuron is to a change in $\\vec x$ relative to $e_i$. The sign of $\\alpha _i$ determines whether $e_i$ is the preferred stimulus of neuron $i$. If $\\alpha$ is positive, the input to $i$ is maximized when $\\vec x$ and $\\vec e_i$ are aligned and pointing in the same direction; if $\\alpha _i$ is negative, input is maximized when the two vectors are aligned but point in opposite directions. $b_i$ determines the baseline activation of the neuron $i$ (activation when $\\vec x = 0$).\n",
      "\n",
      "So far we've been discussing the output $a_i$ of a neuron $i$. How well does $i$ represent $\\vec x$? Or rather, how easy is it to recover $\\vec x$ from $a_i$? Well, it depends. If $m$ (the number of dimensions) is anything greater than $1$, we have lost quite bit of information. At best we know how big the $\\vec e_i$ component of $\\vec x$ is. And if $n$ is $1$, the answer depends on $G$.\n",
      "\n",
      "The NEF insight is that population coding helps you overcome this problem. If you were trying to recover $\\vec x$ from $a_i$, you might write \n",
      "\n",
      "$$\\hat x = g(a_i)$$\n",
      "\n",
      "where $\\hat x$ is an estimate of $\\vec x$. The paragraph above should suggest to you that this is probably not going to work out very well, so try instead\n",
      "\n",
      "$$\\hat x = g(a_1,...,a_n)$$ \n",
      "\n",
      "where $a_1,...,a_n$ are each outputs of individual neurons $1$ through $n$. We have a choice about what $g$ to use, but it turns out (surprisingly!) that a linear transformation works just fine (See SYDE556 Representation lecture or _Neural Engineering_ Chapter 2 by Eliasmith and Anderson). Writing $\\vec a=(a_1,...,a_n)$, we get\n",
      "\n",
      "$$g(\\vec a) = D\\vec a$$\n",
      "\n",
      "where $D:m\\times n$ is a matrix of column vectors $\\vec d_1,...,\\vec d_n$. This gets us \n",
      "\n",
      "$$\\hat x = \\Sigma _{i=1}^n a_i\\vec d_i.$$\n",
      "\n",
      "$D$ is chosen to minimize the mean square error of $\\hat x$. For large enough $n$ (number of neurons), we have $\\epsilon\\propto\\frac 1 {n^2}$ where $\\epsilon$ is the decoding error. Additionally, the NEF models include random noise in the neural signal. Neural signals are actually noisy. This adds an additional error term, which decreases proportionally to $1/n$. That means that after a certain point, random noise dominates the total estimate error. (See SYDE556 Representation lecture.)\n",
      "\n",
      "We can put all this together into NEF (and Nengo) terminology. Consider $n$ neurons indexed $1,...,n$. Let $\\vec x\\in\\mathbb R^m$ be the input vector to be represented, $a_i$ denote the output of the $i^{\\mathrm{th}}$ neuron and $\\hat x$ be the estimate of $\\vec x$ represented by the neurons $1,..,n$. We have\n",
      "\n",
      "\\begin{align}\n",
      "a_i &= f(\\alpha _i\\vec x\\cdot\\vec e_i + b_i) &&\\mathrm{(encoding\\ equation)}\\\\\n",
      "\\hat x &= \\Sigma_{i=1}^n a_i\\vec d_i &&\\mathrm{(decoding\\ equation).}\n",
      "\\end{align}\n",
      "\n",
      "The vectors $\\vec e_1,...,\\vec e_n$ are called encoders, and $\\vec d_1,...,\\vec d_n$ are decoders. Just as above, $\\alpha _1,...,\\alpha _n$ are gain values, and $b_1,...,b_n$ are unit biases. $f$ is the transfer function."
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Implementing an image retrieval system"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Our overall goal is to implement an image buffer into which we can load images after some basic processing (scaling and translation). (Compare with Kosslyn-syle visual buffer.) We are not going to simulate image memory, but we still need some model of how images will be retrieved, and consequently of how they will be stored. We additionally need to decide how the image will be represented in the image buffer. We will also simply assume that images are mono-chromatic at this stage of the model. Eventually, we want to attach this to SOILIE and add color.\n",
      "\n",
      "If we stick with the connection to the mental imagery approach, our image buffer should look like the visual buffer. So the space represented by it should be roughly circular in shape and the receptive fields of the neurons implementing the buffer should be similar to those in V1. Here is one way to implement something to that effect in NEF terms.\n",
      "\n",
      "Let $B=\\{\\mathrm n_1,...,\\mathrm n_{n_B}\\}$ be the ensemble (set of neurons) implementing the image buffer. Clearly, there are $n_B$ neurons in $B$. For $\\mathrm n_i\\in B$ the output is determined by\n",
      "\n",
      "$$a_i = f(\\alpha _i\\vec x\\cdot\\vec e_i + b_i),$$\n",
      "\n",
      "where $\\vec x$ is the input (a vector representation of the raw image). We know that the receptive field of neurons in V1 look like Gabor filters, so the $e_i$ should reflect that. Moreover, all that is needed to constrain the shape of the image buffer is that the $e_1,...,e_{n_B}$ cover a roughly circular area (i.e. they cover most of the area within a circle).\n",
      "\n",
      "A note about image models: there are different ways to model images, namely a discrete/digital model (pixel arrays) versus a continuous/analog model (functions). For what follows, we work with digital images, though it should not be too difficult to adjust the model to work with the assumption that the image is analog.\n",
      "\n",
      "Let's prepare some encoders."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Create encoder neurons\n",
      "#Some code is taken from SYDE556, Spatial Representation lecture (lecture 9)\n",
      "\n",
      "#All images will be on an img_size*img_size canvas.\n",
      "img_size = 50\n",
      "\n",
      "#n_B is as in text above.\n",
      "n_B = 200\n",
      "\n",
      "import numpy\n",
      "import random\n",
      "\n",
      "#Returns a single gabor filter\n",
      "def gabor(size, lambd, theta, psi, sigma, gamma, x_offset, y_offset):\n",
      "    x = numpy.linspace(-1, 1, size)\n",
      "    y = numpy.linspace(-1, 1, size)\n",
      "    X, Y = numpy.meshgrid(x, y)\n",
      "    X = X - x_offset\n",
      "    Y = Y + y_offset\n",
      "\n",
      "    cosTheta = numpy.cos(theta)\n",
      "    sinTheta = numpy.sin(theta)\n",
      "    xTheta = X * cosTheta  + Y * sinTheta\n",
      "    yTheta = -X * sinTheta + Y * cosTheta\n",
      "    e = numpy.exp( -(xTheta**2 + yTheta**2 * gamma**2) / (2 * sigma**2) )\n",
      "    cos = numpy.cos(2 * numpy.pi * xTheta / lambd + psi)\n",
      "    return e * cos\n",
      "\n",
      "#Returns a gabor filter with placement constraints as in text above\n",
      "def make_random_gabor(size):\n",
      "    sigma = random.uniform(0.1, 0.2)\n",
      "    r = (random.uniform(0, 0.9)-(sigma))**2\n",
      "    th = random.uniform(0, 2*numpy.pi)\n",
      "    return gabor(size, \n",
      "                  lambd=random.uniform(0.3, 0.8),\n",
      "                  theta=random.uniform(0, 2*numpy.pi),\n",
      "                  psi=random.uniform(0, 2*numpy.pi),\n",
      "                  sigma=sigma,\n",
      "                  gamma=random.uniform(0.7, 1),\n",
      "                  x_offset=r*numpy.cos(th),\n",
      "                  y_offset=r*numpy.sin(th))\n",
      "                \n",
      "encoders = [make_random_gabor(img_size) for i in range(n_B)]\n",
      "\n",
      "#normalize encoders\n",
      "encoders = [(1/numpy.linalg.norm(i).flatten())*i for i in encoders]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Display the resulting filters. (Warning: image displayed was generated before normalization was added above.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pylab\n",
      "pylab.figure(figsize=(10,8))\n",
      "for i in range(n_B):\n",
      "    w = i%12\n",
      "    h = i/12\n",
      "    pylab.imshow(encoders[i], extent=(w, w+0.95, h, h+0.95), interpolation='none',\n",
      "                 vmin=-1, vmax=1, cmap='gray')\n",
      "    pylab.xticks([])\n",
      "    pylab.yticks([])\n",
      "pylab.xlim((0, 12))\n",
      "pylab.ylim((0, n_B/12))\n",
      "    \n",
      "pylab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"files/Figures/gabors_for_visualbuffer.svg\">\n",
      "\n",
      "Check that image buffer is roughly circular. (Warning: image displayed was generated before normalization was added above.)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "e = numpy.copy(encoders)\n",
      "e[e<0] = -e[e<0]\n",
      "pylab.imshow(numpy.sum(e, 0), extent=(-1, 1, -1, 1), interpolation='none', vmin=-1, vmax=1, cmap='gray')\n",
      "pylab.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<img src=\"files/Figures/visualbuffer_field.svg\">"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We are going to store many images. It is probably best if we can compress them somehow. It might even be worthwhile to compress the encoders above. It would make the model lighter, but we could argue that it was done for convenience, not for theoretical reasons. Though, we could probably run things pretty fast.\n",
      "\n",
      "Anyway, this section will be about our use of SVD."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}